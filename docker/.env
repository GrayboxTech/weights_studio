# Environment Configuration for Weights Studio

# Ollama Configuration (optional, only if using Ollama as local model provider)
OLLAMA_HOST=localhost
OLLAMA_PORT=11435
OLLAMA_MODEL=qwen2.5:3b-instruct

# gRPC-Web Proxy
VITE_GRPC_WEB_HOST=localhost
VITE_GRPC_WEB_PORT=8080

# Python gRPC Backend (runs on host, not in container)
GRPC_BACKEND_HOST=localhost
GRPC_BACKEND_PORT=50051

# Vite Dev Server
VITE_PORT=5173
VITE_HOST=0.0.0.0
# WeightsStudio Configuration

# Number of batches to prefetch ahead for faster navigation
# Default: 5
# Higher values = more memory usage but smoother navigation
VITE_MAX_PREFETCH_BATCHES=5

# ENVOY Proxy Configuration
ENVOY_HOST=localhost
ENVOY_PORT=8080
ENVOY_ADMIN_PORT=9901